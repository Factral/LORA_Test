{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leons\\AppData\\Local\\miniconda3\\envs\\leon_torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.networks import DemoNet\n",
    "import peft\n",
    "import torch\n",
    "from utils import get_dataset_torch, AverageMeter\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel, im_size, num_classes, class_names, dst_train, dst_test, testloader, trainloader, valoader   = get_dataset_torch('FMNIST', 'data', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ACCURACY = MulticlassAccuracy(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, trainloader, valoader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        data_loop_train = tqdm(enumerate(trainloader), total=len(trainloader), colour='red')\n",
    "        train_accuracy = AverageMeter()\n",
    "        train_loss = AverageMeter()\n",
    "        for _, data in data_loop_train:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = ACCURACY(outputs, labels)\n",
    "\n",
    "            train_accuracy.update(accuracy.item(), inputs.size(0))\n",
    "            train_loss.update(loss.item(), inputs.size(0))\n",
    "            data_loop_train.set_description(f'Epoch {epoch+1}/{epochs}')\n",
    "            data_loop_train.set_postfix(loss=train_loss.avg, accuracy=train_accuracy.avg)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            data_loop_val = tqdm(enumerate(valoader), total=len(valoader), colour='green')\n",
    "            val_accuracy = AverageMeter()\n",
    "            val_loss = AverageMeter()\n",
    "            for _, data in data_loop_val:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                accuracy = ACCURACY(outputs, labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss.update(loss.item(), inputs.size(0))\n",
    "                val_accuracy.update(accuracy.item(), inputs.size(0))\n",
    "                data_loop_val.set_description(f'Epoch {epoch+1}/{epochs}')\n",
    "                data_loop_val.set_postfix(loss=val_loss.avg, accuracy=accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train without lora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 100, 28, 28]           1,000\n",
      "            Conv2d-2          [-1, 100, 14, 14]          90,100\n",
      "            Conv2d-3              [-1, 1, 7, 7]             901\n",
      "            Linear-4                   [-1, 10]             500\n",
      "================================================================\n",
      "Total params: 92,501\n",
      "Trainable params: 92,501\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.75\n",
      "Params size (MB): 0.35\n",
      "Estimated Total Size (MB): 1.10\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = DemoNet().to(device)\n",
    "print(summary(model, (1, 28, 28)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:20<00:00, 80.42it/s, accuracy=0.781, loss=0.569]\n",
      "Epoch 1/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 108.04it/s, accuracy=0.812, loss=0.397]\n",
      "Epoch 2/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:19<00:00, 86.04it/s, accuracy=0.852, loss=0.382]\n",
      "Epoch 2/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 102.02it/s, accuracy=0.398, loss=0.349]\n",
      "Epoch 3/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:20<00:00, 80.64it/s, accuracy=0.868, loss=0.337]\n",
      "Epoch 3/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 105.98it/s, accuracy=0.952, loss=0.341]\n",
      "Epoch 4/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:21<00:00, 78.27it/s, accuracy=0.88, loss=0.308] \n",
      "Epoch 4/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 108.36it/s, accuracy=0.714, loss=0.321]\n",
      "Epoch 5/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:19<00:00, 85.37it/s, accuracy=0.888, loss=0.287]\n",
      "Epoch 5/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 104.45it/s, accuracy=1, loss=0.31]     \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, trainloader, valoader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train with lora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', networks.DemoNet),\n",
       " ('conv1', torch.nn.modules.conv.Conv2d),\n",
       " ('conv2', torch.nn.modules.conv.Conv2d),\n",
       " ('conv3', torch.nn.modules.conv.Conv2d),\n",
       " ('linear', torch.nn.modules.linear.Linear)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n, type(m)) for n, m in DemoNet().named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = peft.LoraConfig(\n",
    "    r=1,\n",
    "    target_modules=[\"conv1\", \"linear\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 168 || all params: 92,669 || trainable%: 0.1813\n"
     ]
    }
   ],
   "source": [
    "model = DemoNet().to(device)\n",
    "model_copy = copy.deepcopy(model)\n",
    "peft_model = peft.get_peft_model(model, config)\n",
    "optimizer = torch.optim.Adam(peft_model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "peft_model.print_trainable_parameters() # previous wights + A, B matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:22<00:00, 76.60it/s, accuracy=0.297, loss=1.72]\n",
      "Epoch 1/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 99.35it/s, accuracy=0.308, loss=1.4]  \n",
      "Epoch 2/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:21<00:00, 76.79it/s, accuracy=0.516, loss=1.28]\n",
      "Epoch 2/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 97.70it/s, accuracy=0.537, loss=1.23]\n",
      "Epoch 3/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:22<00:00, 75.44it/s, accuracy=0.546, loss=1.19]\n",
      "Epoch 3/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:02<00:00, 91.26it/s, accuracy=0.317, loss=1.18]\n",
      "Epoch 4/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:23<00:00, 72.50it/s, accuracy=0.562, loss=1.14]\n",
      "Epoch 4/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:02<00:00, 91.47it/s, accuracy=0.567, loss=1.14] \n",
      "Epoch 5/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:20<00:00, 80.64it/s, accuracy=0.585, loss=1.1]\n",
      "Epoch 5/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 97.71it/s, accuracy=0.444, loss=1.11]\n"
     ]
    }
   ],
   "source": [
    "train(peft_model, optimizer, criterion, trainloader, valoader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New parameter model.conv1.lora_A.default.weight |     9 parameters | updated\n",
      "New parameter model.conv1.lora_B.default.weight |   100 parameters | updated\n",
      "New parameter model.linear.lora_A.default.weight |    49 parameters | updated\n",
      "New parameter model.linear.lora_B.default.weight |    10 parameters | updated\n"
     ]
    }
   ],
   "source": [
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if \"lora\" not in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"New parameter {name:<30} | {param.numel():>5} parameters | updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter model.conv1.base_layer.weight  |   900 parameters | not updated\n",
      "Parameter model.conv1.base_layer.bias    |   100 parameters | not updated\n",
      "Parameter model.conv2.weight             | 90000 parameters | not updated\n",
      "Parameter model.conv2.bias               |   100 parameters | not updated\n",
      "Parameter model.conv3.weight             |   900 parameters | not updated\n",
      "Parameter model.conv3.bias               |     1 parameters | not updated\n",
      "Parameter model.linear.base_layer.weight |   490 parameters | not updated\n",
      "Parameter model.linear.base_layer.bias   |    10 parameters | not updated\n"
     ]
    }
   ],
   "source": [
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if \"lora\" in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"Parameter {name:<30} | {param.numel():>5} parameters | not updated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leon_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
